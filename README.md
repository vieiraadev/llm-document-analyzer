# Analisador de Documentos com IA (RAG Local) üß†üìÑ

Este √© um projeto desenvolvido para **responder automaticamente a perguntas com base em PDFs carregados pelo usu√°rio**, utilizando a arquitetura RAG (Retrieval-Augmented Generation).  
Tudo √© feito com **modelos open-source rodando localmente**, sem custos com API.

---

## üìã Descri√ß√£o do Projeto

A aplica√ß√£o permite:
- Fazer upload de um ou mais arquivos PDF.
- Processar os documentos e gerar embeddings semanticamente relevantes.
- Fazer perguntas em linguagem natural sobre o conte√∫do dos PDFs.
- Obter respostas geradas por uma IA local baseada em LLM.
- Visualizar as perguntas e respostas com uma interface em formato de chat (Voc√™ / Sistema).

A arquitetura RAG combina **busca vetorial com gera√ß√£o por linguagem natural**, oferecendo respostas contextualizadas com base no conte√∫do dos documentos enviados.

---


## üöÄ Funcionalidades

1. **Upload de PDFs**  
   O usu√°rio pode carregar documentos para an√°lise. Os textos s√£o automaticamente extra√≠dos e divididos em partes para indexa√ß√£o.

2. **Busca sem√¢ntica com Embeddings Locais**  
   O sistema gera vetores a partir dos textos dos PDFs e armazena-os em uma base vetorial local (ChromaDB), sem uso de nuvem.

3. **Gera√ß√£o de Respostas com LLM Local**  
   As respostas s√£o geradas usando o modelo open-source `TinyLlama-1.1B-Chat-v1.0`, diretamente na CPU da m√°quina do usu√°rio.

4. **Interface em Estilo de Chat**  
   O usu√°rio interage com o sistema em uma interface simples e elegante, semelhante a um chat, feita com Streamlit.

---

## üõ†Ô∏è Tecnologias Utilizadas

- **Python**
- **Streamlit**: Interface gr√°fica web local
- **LangChain**: Orquestra√ß√£o da arquitetura RAG
- **Transformers (HuggingFace)**: Modelo LLM local (TinyLlama)
- **ChromaDB**: Banco vetorial local
- **PyMuPDF**: Leitura e extra√ß√£o de texto de PDFs
- **sentence-transformers**: Embeddings locais

---
